{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed66b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:11.199270Z",
     "iopub.status.busy": "2024-11-18T12:14:11.198948Z",
     "iopub.status.idle": "2024-11-18T12:14:15.953966Z",
     "shell.execute_reply": "2024-11-18T12:14:15.953068Z"
    },
    "papermill": {
     "duration": 4.763589,
     "end_time": "2024-11-18T12:14:15.956370",
     "exception": false,
     "start_time": "2024-11-18T12:14:11.192781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T\n",
    "from torchvision.ops import nms\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils import DetectionLoss\n",
    "from esanet_model import DetectionModel\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9174e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:15.968656Z",
     "iopub.status.busy": "2024-11-18T12:14:15.967730Z",
     "iopub.status.idle": "2024-11-18T12:14:16.032753Z",
     "shell.execute_reply": "2024-11-18T12:14:16.031869Z"
    },
    "papermill": {
     "duration": 0.073224,
     "end_time": "2024-11-18T12:14:16.034838",
     "exception": false,
     "start_time": "2024-11-18T12:14:15.961614",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bf70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:16.046406Z",
     "iopub.status.busy": "2024-11-18T12:14:16.045703Z",
     "iopub.status.idle": "2024-11-18T12:14:16.061201Z",
     "shell.execute_reply": "2024-11-18T12:14:16.060481Z"
    },
    "id": "8M87Ymw_-Vlp",
    "papermill": {
     "duration": 0.023199,
     "end_time": "2024-11-18T12:14:16.063082",
     "exception": false,
     "start_time": "2024-11-18T12:14:16.039883",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotation_file, img_dir, transform=None, scales=[(16, 16), (32, 32), (64, 64), (128, 128)]):\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "        self.scales = scales  # feature map scales for p1, p2, p3, p4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        image = Image.open(os.path.join(self.img_dir, img_info['file_name'])).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        annotations = self.coco.loadAnns(self.coco.getAnnIds(imgIds=img_id))\n",
    "        labels, boxes = self.generate_targets(annotations, img_info)\n",
    "        return img_id, image, labels, boxes\n",
    "\n",
    "    def generate_targets(self, annotations, img_info):\n",
    "        w_img, h_img = img_info['width'], img_info['height']\n",
    "        labels_list = []\n",
    "        bbox_list = []\n",
    "        \n",
    "        for scale in self.scales:\n",
    "            cls_targets = torch.zeros((scale[1], scale[0]), dtype=torch.int64)  # height, width\n",
    "            bbox_targets = torch.zeros((scale[1], scale[0], 4), dtype=torch.float32)  # height, width, 4\n",
    "            \n",
    "            for ann in annotations:\n",
    "                category = ann['category_id']\n",
    "                bbox = ann['bbox']\n",
    "                center_x = bbox[0] + bbox[2] / 2\n",
    "                center_y = bbox[1] + bbox[3] / 2\n",
    "                scale_x, scale_y = scale[0] / w_img, scale[1] / h_img\n",
    "                grid_x, grid_y = int(center_x * scale_x), int(center_y * scale_y)\n",
    "                \n",
    "                if 0 <= grid_x < scale[0] and 0 <= grid_y < scale[1]:\n",
    "                    cls_targets[grid_y, grid_x] = category\n",
    "                    bbox_targets[grid_y, grid_x] = torch.tensor([\n",
    "                        (center_x * scale_x - grid_x),  # normalized center x\n",
    "                        (center_y * scale_y - grid_y),  # normalized center y\n",
    "                        bbox[2] * scale_x,              # normalized width\n",
    "                        bbox[3] * scale_y               # normalized height\n",
    "                    ])\n",
    "            \n",
    "            labels_list.append(cls_targets)\n",
    "            bbox_list.append(bbox_targets)\n",
    "        \n",
    "        return labels_list, bbox_list\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    img_ids, images, labels_batch, boxes_batch = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    labels_batch = [torch.stack(labels) for labels in zip(*labels_batch)]\n",
    "    boxes_batch = [torch.stack(boxes) for boxes in zip(*boxes_batch)]\n",
    "    return img_ids, images, labels_batch, boxes_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9b354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:16.075184Z",
     "iopub.status.busy": "2024-11-18T12:14:16.074926Z",
     "iopub.status.idle": "2024-11-18T12:14:16.113146Z",
     "shell.execute_reply": "2024-11-18T12:14:16.112164Z"
    },
    "papermill": {
     "duration": 0.047086,
     "end_time": "2024-11-18T12:14:16.115116",
     "exception": false,
     "start_time": "2024-11-18T12:14:16.068030",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Define transforms and initialize DataLoader for training and validation sets\n",
    "transform_train = T.Compose([\n",
    "    T.Resize((512, 512)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((512, 512)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set dataset paths for training and validation\n",
    "train_annotation_file = '../IP102_Rice/annotations_train_rice.json'\n",
    "train_img_dir = '../IP102_Rice/images/train'\n",
    "val_annotation_file = '../IP102_Rice/annotations_val_rice.json'\n",
    "val_img_dir = '../IP102_Rice/images/val'\n",
    "\n",
    "# Initialize datasets and DataLoaders for train and validation sets\n",
    "train_dataset = CustomDataset(train_annotation_file, train_img_dir, transform=transform_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataset = CustomDataset(val_annotation_file, val_img_dir, transform=transform_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=5, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa6207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:16.126456Z",
     "iopub.status.busy": "2024-11-18T12:14:16.126198Z",
     "iopub.status.idle": "2024-11-18T12:14:18.565693Z",
     "shell.execute_reply": "2024-11-18T12:14:18.564736Z"
    },
    "papermill": {
     "duration": 2.448878,
     "end_time": "2024-11-18T12:14:18.569133",
     "exception": false,
     "start_time": "2024-11-18T12:14:16.120255",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DetectionModel and DetectionLoss\n",
    "num_classes = len(train_dataset.coco.getCatIds()) + 1\n",
    "model = DetectionModel(num_classes=num_classes).to(device)\n",
    "print(summary(model, input_size=(1, 3, 512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912b94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:18.583661Z",
     "iopub.status.busy": "2024-11-18T12:14:18.583093Z",
     "iopub.status.idle": "2024-11-18T12:14:18.589066Z",
     "shell.execute_reply": "2024-11-18T12:14:18.588215Z"
    },
    "papermill": {
     "duration": 0.015202,
     "end_time": "2024-11-18T12:14:18.590955",
     "exception": false,
     "start_time": "2024-11-18T12:14:18.575753",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = DetectionLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1839858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:18.606464Z",
     "iopub.status.busy": "2024-11-18T12:14:18.606189Z",
     "iopub.status.idle": "2024-11-18T12:14:18.613740Z",
     "shell.execute_reply": "2024-11-18T12:14:18.612894Z"
    },
    "papermill": {
     "duration": 0.016751,
     "end_time": "2024-11-18T12:14:18.615585",
     "exception": false,
     "start_time": "2024-11-18T12:14:18.598834",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for img_ids, images, labels_list, boxes_list in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cls_logits_list, bbox_preds_list = model(images)\n",
    "        loss = 0\n",
    "\n",
    "        for scale_idx in range(len(cls_logits_list)):\n",
    "            cls_logits = cls_logits_list[scale_idx]\n",
    "            bbox_preds = bbox_preds_list[scale_idx]\n",
    "            labels = labels_list[scale_idx].to(device)\n",
    "            boxes = boxes_list[scale_idx].to(device)\n",
    "\n",
    "            scale_loss = criterion(cls_logits, bbox_preds, labels, boxes)\n",
    "            loss += scale_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3250f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:18.629880Z",
     "iopub.status.busy": "2024-11-18T12:14:18.629323Z",
     "iopub.status.idle": "2024-11-18T12:14:18.642050Z",
     "shell.execute_reply": "2024-11-18T12:14:18.641323Z"
    },
    "papermill": {
     "duration": 0.02196,
     "end_time": "2024-11-18T12:14:18.643998",
     "exception": false,
     "start_time": "2024-11-18T12:14:18.622038",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    results_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_ids, images, labels_per_scale, boxes_per_scale in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            cls_logits_list, bbox_preds_list = model(images)\n",
    "            loss = 0\n",
    "\n",
    "            # Calculate loss for each scale\n",
    "            for scale_idx, (cls_logits, bbox_preds) in enumerate(zip(cls_logits_list, bbox_preds_list)):\n",
    "                labels = labels_per_scale[scale_idx].to(device)\n",
    "                boxes = boxes_per_scale[scale_idx].to(device)\n",
    "\n",
    "                scale_loss = criterion(cls_logits, bbox_preds, labels, boxes)\n",
    "                loss += scale_loss\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Process detections for NMS\n",
    "            for scale_idx, (cls_logits, bbox_preds) in enumerate(zip(cls_logits_list, bbox_preds_list)):\n",
    "                B, H, W, C = cls_logits.shape\n",
    "                cls_probs = torch.sigmoid(cls_logits).view(B, H * W, C)\n",
    "                bbox_preds = bbox_preds.view(B, H * W, 4)\n",
    "\n",
    "                for img_idx in range(B):\n",
    "                    scores, classes = cls_probs[img_idx].max(dim=1)\n",
    "                    boxes = bbox_preds[img_idx]\n",
    "\n",
    "                    # Apply NMS\n",
    "                    keep = nms(boxes, scores, iou_threshold=0.5)\n",
    "                    filtered_boxes = boxes[keep]\n",
    "                    filtered_scores = scores[keep]\n",
    "                    filtered_classes = classes[keep]\n",
    "\n",
    "                    # Scale and convert coordinates\n",
    "                    filtered_boxes = filtered_boxes * torch.tensor([W, H, W, H], device=device).float()\n",
    "                    filtered_boxes = filtered_boxes[:, [1, 0, 3, 2]]  # convert to [y1, x1, y2, x2] format\n",
    "\n",
    "                    # Store results\n",
    "                    results_list.extend([\n",
    "                        {\n",
    "                            \"image_id\": int(img_ids[img_idx]),\n",
    "                            \"category_id\": int(filtered_classes[j].item()),\n",
    "                            \"bbox\": [float(coord) for coord in filtered_boxes[j].tolist()],\n",
    "                            \"score\": float(filtered_scores[j].item())\n",
    "                        }\n",
    "                        for j in range(len(filtered_scores))\n",
    "                    ])\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        avg_val_loss = running_loss / len(dataloader)\n",
    "        return avg_val_loss, results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3aec25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:18.658295Z",
     "iopub.status.busy": "2024-11-18T12:14:18.658030Z",
     "iopub.status.idle": "2024-11-18T12:14:18.663300Z",
     "shell.execute_reply": "2024-11-18T12:14:18.662453Z"
    },
    "papermill": {
     "duration": 0.014726,
     "end_time": "2024-11-18T12:14:18.665281",
     "exception": false,
     "start_time": "2024-11-18T12:14:18.650555",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def coco_eval(results_list, val_annotation_file):\n",
    "    if results_list:\n",
    "        coco_gt = COCO(val_annotation_file)  # Load ground truth annotations\n",
    "        coco_dt = coco_gt.loadRes(results_list)  # Load the results from predictions\n",
    "\n",
    "        # Perform COCO evaluation using bounding boxes (iouType='bbox')\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "    else:\n",
    "        print(\"No valid results to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08526173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T12:14:18.679401Z",
     "iopub.status.busy": "2024-11-18T12:14:18.679137Z",
     "iopub.status.idle": "2024-11-18T13:34:38.180075Z",
     "shell.execute_reply": "2024-11-18T13:34:38.179145Z"
    },
    "papermill": {
     "duration": 4819.510311,
     "end_time": "2024-11-18T13:34:38.182142",
     "exception": false,
     "start_time": "2024-11-18T12:14:18.671831",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Training loop encapsulated in a function.\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss_train = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_loss_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fa7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T13:34:39.182375Z",
     "iopub.status.busy": "2024-11-18T13:34:39.181497Z",
     "iopub.status.idle": "2024-11-18T13:36:02.406010Z",
     "shell.execute_reply": "2024-11-18T13:36:02.405081Z"
    },
    "papermill": {
     "duration": 83.744532,
     "end_time": "2024-11-18T13:36:02.407977",
     "exception": false,
     "start_time": "2024-11-18T13:34:38.663445",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Validate after training is complete.\n",
    "avg_val_loss, results_list = validate(model, val_dataloader, criterion, device)\n",
    "print(f\"Validation Loss after Training: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e648f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T13:36:03.449265Z",
     "iopub.status.busy": "2024-11-18T13:36:03.448919Z",
     "iopub.status.idle": "2024-11-18T13:36:08.676838Z",
     "shell.execute_reply": "2024-11-18T13:36:08.675837Z"
    },
    "papermill": {
     "duration": 5.761048,
     "end_time": "2024-11-18T13:36:08.679019",
     "exception": false,
     "start_time": "2024-11-18T13:36:02.917971",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model after training.\n",
    "coco_eval(results_list, val_annotation_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6112251,
     "sourceId": 9941203,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 208148552,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 208148916,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 208148449,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 208148027,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 208150242,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 208149238,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4936.454674,
   "end_time": "2024-11-18T13:36:11.879162",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T12:13:55.424488",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
